#hide
get_ipython().getoutput("pip install -Uqq fastbook")
import fastbook
fastbook.setup_book()
#hide
from fastbook import *


from fastai.vision.all import *
path = untar_data(URLs.PETS)


#hide
Path.BASE_PATH = path


fname = (path/"images").ls()[0]
fname


pets = DataBlock(blocks = (ImageBlock, CategoryBlock),
                 get_items=get_image_files, 
                 splitter=RandomSplitter(seed=42),
                 get_y=using_attr(RegexLabeller(r'(.+)_\d+.jpg$'), 'name'),
                 item_tfms=Resize(460),
                 batch_tfms=setup_aug_tfms([
                     Rotate(draw=30, p=1, size=224), 
                     Zoom(draw=1.2, p=1., size=224),
                     Warp(draw_x=-0.2, draw_y=0.2, p=1., size=224)])
                 )

dls = pets.dataloaders(path/"images")
#pets.summary(path/"images")



dls.train.show_batch(nrows=2, ncols=5)



learn = cnn_learner(dls, resnet50, metrics=error_rate).to_fp16()


learn.fit_one_cycle(3, 3e-3)


learn.unfreeze()
lr_found = learn.lr_find()
lr_found


base_lr = 4.365158383734524e-05
mult_lr = 100
learn.fit_one_cycle(6, slice(base_lr/mult_lr, base_lr))


learn.recorder.plot_loss()


sample = (path/'images').ls()[1,10,11]
sample, learn.predict(sample[1])


interp = ClassificationInterpretation.from_learner(learn)
interp.plot_confusion_matrix(figsize=(12,12), dpi=60)


interp.most_confused(min_val=5)


x, y = dls.one_batch()
preds, targets = learn.get_preds(dl=[(x,y)])
len(x), len(y), len(preds[0]), preds.shape, sum(preds[0])


act = torch.randn((6, 4)) * 2

act, act[0].sigmoid(), torch.softmax(act, dim=1)


sm_act = torch.softmax(act, dim=1)
t_indexes = torch.tensor([0,2,1,1,2,3])
indexes = range(6)
-sm_act[indexes, t_indexes], F.nll_loss(sm_act, t_indexes, reduction='none')


-torch.log(sm_act[indexes, t_indexes]), nn.CrossEntropyLoss(reduction='none')(act, t_indexes)


-torch.log(sm_act[indexes, t_indexes]).mean(), nn.CrossEntropyLoss()(act, t_indexes)


plot_function(torch.log, min=0, max=4)
