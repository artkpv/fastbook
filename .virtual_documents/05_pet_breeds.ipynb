#hide
get_ipython().getoutput("pip install -Uqq fastbook")
import fastbook
fastbook.setup_book()


#hide
from fastbook import *


from fastai.vision.all import *
path = untar_data(URLs.PETS)


#hide
Path.BASE_PATH = path


path.ls()


(path/"images").ls()


fname = (path/"images").ls()[0]


re.findall(r'(.+)_\d+.jpg$', fname.name)


pets = DataBlock(blocks = (ImageBlock, CategoryBlock),
                 get_items=get_image_files, 
                 splitter=RandomSplitter(seed=42),
                 get_y=using_attr(RegexLabeller(r'(.+)_\d+.jpg$'), 'name'),
                 item_tfms=Resize(460),
                 batch_tfms=aug_transforms(size=224, min_scale=0.75))
dls = pets.dataloaders(path/"images")


dblock1 = DataBlock(blocks=(ImageBlock(), CategoryBlock()),
                   get_y=parent_label,
                   item_tfms=Resize(460))
# Place an image in the 'images/grizzly.jpg' subfolder where this notebook is located before running this
dls1 = dblock1.dataloaders([(Path.cwd()/'images'/'grizzly.jpg')]*100, bs=8)
dls1.train.get_idxs = lambda: Inf.ones
x,y = dls1.valid.one_batch()
xorig = x 
_,axs = subplots(1, 2)

x1 = TensorImage(x.clone())
x1 = x1.affine_coord(sz=224)
x1 = x1.rotate(draw=30, p=1.)
x1 = x1.zoom(draw=1.2, p=1.)
x1 = x1.warp(draw_x=-0.2, draw_y=0.2, p=1.)

tfms = setup_aug_tfms([Rotate(draw=30, p=1, size=224), Zoom(draw=1.2, p=1., size=224),
                       Warp(draw_x=-0.2, draw_y=0.2, p=1., size=224)])
x = Pipeline(tfms)(x.clone())
#x.affine_coord(coord_tfm=coord_tfm, sz=size, mode=mode, pad_mode=pad_mode)
TensorImage(xorig[5]).show()
TensorImage(x[5]).show()
TensorImage(x1[5]).show()





dls.show_batch(nrows=10, ncols=3)


pets1 = DataBlock(blocks = (ImageBlock, CategoryBlock),
                 get_items=get_image_files, 
                 splitter=RandomSplitter(seed=42),
                 get_y=using_attr(RegexLabeller(r'(.+)_\d+.jpg$'), 'name'),
                 item_tfms=Resize(460),
                 batch_tfms=setup_aug_tfms([
                     Rotate(draw=30, p=1, size=224), 
                     Zoom(draw=1.2, p=1., size=224),
                     Warp(draw_x=-0.2, draw_y=0.2, p=1., size=224)])
                 )
pets1.summary(path/"images")
dls1 = pets.dataloaders(path/"images")


learn = cnn_learner(dls, resnet34, metrics=error_rate)
learn.fine_tune(2)


x,y = dls.one_batch()


y


preds,_ = learn.get_preds(dl=[(x,y)])
preds[0]


len(preds[0]),preds[0].sum()


plot_function(torch.sigmoid, min=-4,max=4)


#hide
torch.random.manual_seed(42);


acts = torch.randn((6,2))*2
acts


acts.sigmoid()


(acts[:,0]-acts[:,1]).sigmoid()


sm_acts = torch.softmax(acts, dim=1)
sm_acts


targ = tensor([0,1,0,1,1,0])


sm_acts


idx = range(6)
sm_acts[idx, targ]


from IPython.display import HTML
df = pd.DataFrame(sm_acts, columns=["3","7"])
df['targ'] = targ
df['idx'] = idx
df['result'] = sm_acts[range(6), targ]
t = df.style.hide_index()
#To have html code compatible with our script
html = t._repr_html_().split('</style>')[1]
html = re.sub(r'<table id="([^"]+)"\s*>', r'<table >', html)
display(HTML(html))


-sm_acts[idx, targ]


F.nll_loss(sm_acts, targ, reduction='none')


plot_function(torch.log, min=0,max=1, ty='log(x)', tx='x')


plot_function(lambda x: -1*torch.log(x), min=0,max=1, tx='x', ty='- log(x)', title = 'Log Loss when true label = 1')


from IPython.display import HTML
df['loss'] = -torch.log(tensor(df['result']))
t = df.style.hide_index()
#To have html code compatible with our script
html = t._repr_html_().split('</style>')[1]
html = re.sub(r'<table id="([^"]+)"\s*>', r'<table >', html)
display(HTML(html))


loss_func = nn.CrossEntropyLoss()


loss_func(acts, targ)


F.cross_entropy(acts, targ)


nn.CrossEntropyLoss(reduction='none')(acts, targ)


interp = ClassificationInterpretation.from_learner(learn)
interp.plot_confusion_matrix(figsize=(12,12), dpi=60)


interp.most_confused(min_val=5)


learn = cnn_learner(dls, resnet34, metrics=error_rate)
learn.fine_tune(1, base_lr=0.1)


learn = cnn_learner(dls, resnet34, metrics=error_rate)
lr_min,lr_steep = learn.lr_find(suggest_funcs=(minimum, steep))


print(f"Minimum/10: {lr_min:.2e}, steepest point: {lr_steep:.2e}")


learn = cnn_learner(dls, resnet34, metrics=error_rate)
learn.fine_tune(2, base_lr=3e-3)


get_ipython().run_line_magic('pinfo2',  'learn.fine_tune')


learn = cnn_learner(dls, resnet34, metrics=error_rate)
learn.fit_one_cycle(3, 3e-3)


learn.unfreeze()


learn.lr_find()


learn.fit_one_cycle(6, lr_max=1e-5)


learn = cnn_learner(dls, resnet34, metrics=error_rate)
learn.fit_one_cycle(3, 3e-3)
learn.unfreeze()
learn.fit_one_cycle(12, lr_max=slice(1e-6,1e-4))


learn.recorder.plot_loss()


from fastai.callback.fp16 import *
learn = cnn_learner(dls, resnet50, metrics=error_rate).to_fp16()
learn.fine_tune(6, freeze_epochs=3)



